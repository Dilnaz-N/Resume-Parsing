{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "minipro3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKQ28jR1X4Jq",
        "outputId": "3989c4b6-c65d-462d-a50b-17f0be31e998"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9reTZNSAvmup"
      },
      "source": [
        "import pickle\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaJKcuPBvmuu"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/gayathri.pkl\", 'rb') as f:\n",
        "        gayathri=pickle.load( f)\n",
        "#gayathri"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsTfKaQevmuw"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/dilnaz.pkl\", 'rb') as f:\n",
        "        dilnaz=pickle.load( f)\n",
        "#dilnaz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOyCWV6kvmux"
      },
      "source": [
        "with open(r\"/content/drive/MyDrive/arya.pkl\", 'rb') as f:\n",
        "        arya=pickle.load( f)\n",
        "#arya"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pno5bKKhvmuy"
      },
      "source": [
        "with open(r\"/content/drive/MyDrive/merlin.pkl\", 'rb') as f:\n",
        "        merlin=pickle.load( f)\n",
        "#merlin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i5ogzt2vmuz"
      },
      "source": [
        "with open(r\"/content/drive/MyDrive/ashritha1.pkl\", 'rb') as f:\n",
        "        ashritha=pickle.load( f)\n",
        "#ashritha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jhvUKwovmuz"
      },
      "source": [
        "with open(r\"/content/drive/MyDrive/aravind.pkl\", 'rb') as f:\n",
        "        aravind=pickle.load( f)\n",
        "#aravind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKAv-eKMvmu0"
      },
      "source": [
        "train_data=merlin+gayathri+ashritha+arya+aravind+dilnaz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gtRshgjvmu1",
        "outputId": "bb62a961-82ff-4b0d-868a-79884ea85cb2"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKehlvyjvmu4"
      },
      "source": [
        "train=train_data\n",
        "#del train[20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_JHpKu2vmu4",
        "outputId": "c1bd68ab-52d2-462d-80e2-f6f895be5cb7"
      },
      "source": [
        "len(train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPF6-QJBkxpy",
        "outputId": "8358022e-ecf2-4975-a326-08cbc1a689e5"
      },
      "source": [
        "!pip install spacy==2.1.4\n",
        "import random\n",
        "import spacy\n",
        "from spacy.util import minibatch, compounding\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy==2.1.4 in /usr/local/lib/python3.7/dist-packages (2.1.4)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.0.5)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (0.9.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.23.0)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (0.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (1.19.5)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.4) (2.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.4) (4.41.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.4) (2021.5.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_YzTC6vvmu5",
        "outputId": "796578c8-66f5-4082-8cb0-d62ec3c251b8"
      },
      "source": [
        "\n",
        "def train_spacy(TRAIN_DATA, iterations):\n",
        "\n",
        "    #Create the blank spacy model\n",
        "    nlp = spacy.blank(\"en\")\n",
        "    \n",
        "    #add the ner component to the pipeline if it's not there\n",
        "    if \"ner\" not in nlp.pipe_names:\n",
        "        ner = nlp.create_pipe(\"ner\")\n",
        "        nlp.add_pipe(ner, last=True)\n",
        "    \n",
        "    #add all labels to the spaCy model\n",
        "    for _, annotations in TRAIN_DATA:\n",
        "        for ent in annotations.get(\"entities\"):\n",
        "            ner.add_label(ent[2])\n",
        "    \n",
        "    #eliminate the effect of the training on other pipes and\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "    \n",
        "    #begin training\n",
        "    with nlp.disable_pipes(*other_pipes):\n",
        "        optimizer = nlp.begin_training()\n",
        "        for itn in range(iterations):\n",
        "            print(\"Starting iteration \" + str(itn))\n",
        "            random.shuffle(TRAIN_DATA)\n",
        "            losses = {}\n",
        "            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "\n",
        "            #for text, annotations in TRAIN_DATA:\n",
        "                nlp.update(\n",
        "                            texts,\n",
        "                            annotations,\n",
        "                            drop=0.2,\n",
        "                            sgd=optimizer,\n",
        "                            losses=losses,)\n",
        "                print(\"Losses\", losses)\n",
        "    return (nlp)\n",
        "\n",
        "#run function and create a trained model\n",
        "trained_nlp = train_spacy(train, 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting iteration 0\n",
            "Losses {'ner': 10419.80241394043}\n",
            "Losses {'ner': 24248.365005493164}\n",
            "Losses {'ner': 35217.08940124512}\n",
            "Losses {'ner': 47364.74256896973}\n",
            "Losses {'ner': 54846.43348693848}\n",
            "Losses {'ner': 61540.11332702637}\n",
            "Losses {'ner': 64704.72473526001}\n",
            "Losses {'ner': 66590.15138244629}\n",
            "Losses {'ner': 68348.77535629272}\n",
            "Losses {'ner': 70449.55519485474}\n",
            "Losses {'ner': 72533.97481155396}\n",
            "Losses {'ner': 73577.0599451065}\n",
            "Losses {'ner': 73913.0268699862}\n",
            "Losses {'ner': 74918.13005897775}\n",
            "Starting iteration 1\n",
            "Losses {'ner': 1347.6853256225586}\n",
            "Losses {'ner': 3087.1431064605713}\n",
            "Losses {'ner': 4333.6170082092285}\n",
            "Losses {'ner': 5773.01411151886}\n",
            "Losses {'ner': 7494.38760471344}\n",
            "Losses {'ner': 9598.327946662903}\n",
            "Losses {'ner': 10718.036367416382}\n",
            "Losses {'ner': 12096.974113464355}\n",
            "Losses {'ner': 13376.602896690369}\n",
            "Losses {'ner': 13790.600826144218}\n",
            "Losses {'ner': 15122.069345355034}\n",
            "Losses {'ner': 16068.901802897453}\n",
            "Losses {'ner': 17824.611538767815}\n",
            "Losses {'ner': 18387.908960223198}\n",
            "Starting iteration 2\n",
            "Losses {'ner': 1274.1417016983032}\n",
            "Losses {'ner': 2358.3207545280457}\n",
            "Losses {'ner': 3795.888650417328}\n",
            "Losses {'ner': 5032.981632232666}\n",
            "Losses {'ner': 6008.218011856079}\n",
            "Losses {'ner': 7532.126419067383}\n",
            "Losses {'ner': 8203.202978610992}\n",
            "Losses {'ner': 8946.848264217377}\n",
            "Losses {'ner': 9442.86567401886}\n",
            "Losses {'ner': 10789.838089942932}\n",
            "Losses {'ner': 11691.06823015213}\n",
            "Losses {'ner': 13297.720856189728}\n",
            "Losses {'ner': 14500.361713886261}\n",
            "Losses {'ner': 15456.098205804825}\n",
            "Starting iteration 3\n",
            "Losses {'ner': 1430.1961860656738}\n",
            "Losses {'ner': 2722.105625152588}\n",
            "Losses {'ner': 4346.600856781006}\n",
            "Losses {'ner': 5239.425738334656}\n",
            "Losses {'ner': 5898.8180685043335}\n",
            "Losses {'ner': 6816.23087310791}\n",
            "Losses {'ner': 7295.117853164673}\n",
            "Losses {'ner': 8588.88886833191}\n",
            "Losses {'ner': 9569.316368103027}\n",
            "Losses {'ner': 9990.761022567749}\n",
            "Losses {'ner': 11310.691886425018}\n",
            "Losses {'ner': 12347.693596839905}\n",
            "Losses {'ner': 13277.92426109314}\n",
            "Losses {'ner': 14171.49265575409}\n",
            "Starting iteration 4\n",
            "Losses {'ner': 832.5151348114014}\n",
            "Losses {'ner': 1817.8120303153992}\n",
            "Losses {'ner': 2490.2820456027985}\n",
            "Losses {'ner': 4140.894876718521}\n",
            "Losses {'ner': 5175.809655427933}\n",
            "Losses {'ner': 6170.557109117508}\n",
            "Losses {'ner': 6779.430346727371}\n",
            "Losses {'ner': 7827.183998346329}\n",
            "Losses {'ner': 8349.344768762589}\n",
            "Losses {'ner': 9403.928786039352}\n",
            "Losses {'ner': 10645.498343229294}\n",
            "Losses {'ner': 11548.9514336586}\n",
            "Losses {'ner': 12055.354805588722}\n",
            "Losses {'ner': 12738.39777457714}\n",
            "Starting iteration 5\n",
            "Losses {'ner': 891.6300182342529}\n",
            "Losses {'ner': 1542.3624027371407}\n",
            "Losses {'ner': 2519.06905823946}\n",
            "Losses {'ner': 3749.3519518971443}\n",
            "Losses {'ner': 4986.427985966206}\n",
            "Losses {'ner': 6007.331868946552}\n",
            "Losses {'ner': 7596.053720295429}\n",
            "Losses {'ner': 8441.18826085329}\n",
            "Losses {'ner': 9252.814248383045}\n",
            "Losses {'ner': 10181.952930271626}\n",
            "Losses {'ner': 10902.2893653512}\n",
            "Losses {'ner': 11515.462043583393}\n",
            "Losses {'ner': 12656.277032673359}\n",
            "Losses {'ner': 13431.123442947865}\n",
            "Starting iteration 6\n",
            "Losses {'ner': 564.4749329090118}\n",
            "Losses {'ner': 1819.413919210434}\n",
            "Losses {'ner': 2965.1357777118683}\n",
            "Losses {'ner': 3885.2053587436676}\n",
            "Losses {'ner': 4240.9634301662445}\n",
            "Losses {'ner': 4695.178219199181}\n",
            "Losses {'ner': 5716.324388861656}\n",
            "Losses {'ner': 6780.878012061119}\n",
            "Losses {'ner': 7336.778932929039}\n",
            "Losses {'ner': 8074.085422873497}\n",
            "Losses {'ner': 9144.3292812109}\n",
            "Losses {'ner': 10193.782227396965}\n",
            "Losses {'ner': 11754.280579447746}\n",
            "Losses {'ner': 12725.78383910656}\n",
            "Starting iteration 7\n",
            "Losses {'ner': 1066.7869634628296}\n",
            "Losses {'ner': 2259.6372032165527}\n",
            "Losses {'ner': 3228.6747074127197}\n",
            "Losses {'ner': 3683.4791238307953}\n",
            "Losses {'ner': 4314.488213300705}\n",
            "Losses {'ner': 4822.339142799377}\n",
            "Losses {'ner': 5458.733612060547}\n",
            "Losses {'ner': 6209.955377101898}\n",
            "Losses {'ner': 7861.6213002204895}\n",
            "Losses {'ner': 8745.168655872345}\n",
            "Losses {'ner': 10155.589977741241}\n",
            "Losses {'ner': 10945.883490085602}\n",
            "Losses {'ner': 11793.937770843506}\n",
            "Losses {'ner': 13571.233346939087}\n",
            "Starting iteration 8\n",
            "Losses {'ner': 780.1148729324341}\n",
            "Losses {'ner': 1479.4063467979431}\n",
            "Losses {'ner': 2562.0148882865906}\n",
            "Losses {'ner': 3396.8689661026}\n",
            "Losses {'ner': 5090.261666297913}\n",
            "Losses {'ner': 6076.1786642074585}\n",
            "Losses {'ner': 7087.740386962891}\n",
            "Losses {'ner': 7652.795146226883}\n",
            "Losses {'ner': 8441.596819639206}\n",
            "Losses {'ner': 9206.23370051384}\n",
            "Losses {'ner': 9768.557943344116}\n",
            "Losses {'ner': 10921.895400047302}\n",
            "Losses {'ner': 12248.629928588867}\n",
            "Losses {'ner': 12992.380027294159}\n",
            "Starting iteration 9\n",
            "Losses {'ner': 1258.095700263977}\n",
            "Losses {'ner': 2323.5864248275757}\n",
            "Losses {'ner': 2800.771050453186}\n",
            "Losses {'ner': 3894.188895702362}\n",
            "Losses {'ner': 4196.6287115216255}\n",
            "Losses {'ner': 5610.738957226276}\n",
            "Losses {'ner': 6421.683850109577}\n",
            "Losses {'ner': 7546.115017712116}\n",
            "Losses {'ner': 8427.020808041096}\n",
            "Losses {'ner': 9322.386256039143}\n",
            "Losses {'ner': 10214.29568940401}\n",
            "Losses {'ner': 11083.371855318546}\n",
            "Losses {'ner': 11759.497047960758}\n",
            "Losses {'ner': 12450.231749355793}\n",
            "Starting iteration 10\n",
            "Losses {'ner': 792.1111731529236}\n",
            "Losses {'ner': 1384.9393694400787}\n",
            "Losses {'ner': 2218.099041700363}\n",
            "Losses {'ner': 3217.1919219493866}\n",
            "Losses {'ner': 4376.073715925217}\n",
            "Losses {'ner': 5219.187454938889}\n",
            "Losses {'ner': 5729.51736998558}\n",
            "Losses {'ner': 7212.5365998744965}\n",
            "Losses {'ner': 8097.693796873093}\n",
            "Losses {'ner': 9214.416704893112}\n",
            "Losses {'ner': 10114.290678739548}\n",
            "Losses {'ner': 10784.014937639236}\n",
            "Losses {'ner': 11181.110089421272}\n",
            "Losses {'ner': 12290.898209691048}\n",
            "Starting iteration 11\n",
            "Losses {'ner': 1181.052526473999}\n",
            "Losses {'ner': 2003.9783511161804}\n",
            "Losses {'ner': 3320.029279232025}\n",
            "Losses {'ner': 3976.0045614242554}\n",
            "Losses {'ner': 4842.736245632172}\n",
            "Losses {'ner': 5367.323705196381}\n",
            "Losses {'ner': 6126.721705913544}\n",
            "Losses {'ner': 6978.795596599579}\n",
            "Losses {'ner': 7529.833722352982}\n",
            "Losses {'ner': 8715.618702173233}\n",
            "Losses {'ner': 10103.623161554337}\n",
            "Losses {'ner': 10948.128600120544}\n",
            "Losses {'ner': 12029.35082435608}\n",
            "Losses {'ner': 12608.720758676529}\n",
            "Starting iteration 12\n",
            "Losses {'ner': 706.1031775474548}\n",
            "Losses {'ner': 1675.4291710853577}\n",
            "Losses {'ner': 2790.240463733673}\n",
            "Losses {'ner': 3181.7495106458664}\n",
            "Losses {'ner': 4332.0220803022385}\n",
            "Losses {'ner': 5036.304603457451}\n",
            "Losses {'ner': 6468.319541811943}\n",
            "Losses {'ner': 7820.55306661129}\n",
            "Losses {'ner': 8329.485237002373}\n",
            "Losses {'ner': 9016.43355691433}\n",
            "Losses {'ner': 9941.016400694847}\n",
            "Losses {'ner': 10420.746130347252}\n",
            "Losses {'ner': 11712.566673636436}\n",
            "Losses {'ner': 12871.247041106224}\n",
            "Starting iteration 13\n",
            "Losses {'ner': 806.2671446800232}\n",
            "Losses {'ner': 1801.7535948753357}\n",
            "Losses {'ner': 2438.785834789276}\n",
            "Losses {'ner': 3630.58531332016}\n",
            "Losses {'ner': 4506.145844936371}\n",
            "Losses {'ner': 5031.81203186512}\n",
            "Losses {'ner': 5592.475848078728}\n",
            "Losses {'ner': 6985.25304210186}\n",
            "Losses {'ner': 7550.450215578079}\n",
            "Losses {'ner': 8486.345871210098}\n",
            "Losses {'ner': 9533.223953485489}\n",
            "Losses {'ner': 10437.077892541885}\n",
            "Losses {'ner': 10919.660840272903}\n",
            "Losses {'ner': 11861.212203264236}\n",
            "Starting iteration 14\n",
            "Losses {'ner': 1368.3336639404297}\n",
            "Losses {'ner': 2258.515944480896}\n",
            "Losses {'ner': 2868.693444252014}\n",
            "Losses {'ner': 3720.7436113357544}\n",
            "Losses {'ner': 4253.475937366486}\n",
            "Losses {'ner': 5044.50838136673}\n",
            "Losses {'ner': 6035.9050488471985}\n",
            "Losses {'ner': 6925.175940036774}\n",
            "Losses {'ner': 7449.175349473953}\n",
            "Losses {'ner': 8955.30311512947}\n",
            "Losses {'ner': 9893.4379093647}\n",
            "Losses {'ner': 10875.5422976017}\n",
            "Losses {'ner': 11205.29883980751}\n",
            "Losses {'ner': 11689.940967559814}\n",
            "Starting iteration 15\n",
            "Losses {'ner': 761.6898999214172}\n",
            "Losses {'ner': 1093.0188059806824}\n",
            "Losses {'ner': 2050.840663909912}\n",
            "Losses {'ner': 2654.712894797325}\n",
            "Losses {'ner': 3865.806194663048}\n",
            "Losses {'ner': 5014.6874359846115}\n",
            "Losses {'ner': 5850.01863181591}\n",
            "Losses {'ner': 6593.59851539135}\n",
            "Losses {'ner': 7443.474457621574}\n",
            "Losses {'ner': 7880.496793150902}\n",
            "Losses {'ner': 8331.10117661953}\n",
            "Losses {'ner': 9411.883612513542}\n",
            "Losses {'ner': 10548.411040186882}\n",
            "Losses {'ner': 11341.968119978905}\n",
            "Starting iteration 16\n",
            "Losses {'ner': 973.6630153656006}\n",
            "Losses {'ner': 1911.464641571045}\n",
            "Losses {'ner': 2642.2739934921265}\n",
            "Losses {'ner': 3746.6197118759155}\n",
            "Losses {'ner': 3941.0381109155715}\n",
            "Losses {'ner': 5380.914808932692}\n",
            "Losses {'ner': 6354.949703875929}\n",
            "Losses {'ner': 7035.592948619276}\n",
            "Losses {'ner': 7872.062196914107}\n",
            "Losses {'ner': 8601.373997870833}\n",
            "Losses {'ner': 9309.238234702498}\n",
            "Losses {'ner': 9921.963620845228}\n",
            "Losses {'ner': 10521.62474406138}\n",
            "Losses {'ner': 11619.580744389445}\n",
            "Starting iteration 17\n",
            "Losses {'ner': 854.134916305542}\n",
            "Losses {'ner': 1668.6396124362946}\n",
            "Losses {'ner': 2867.781933069229}\n",
            "Losses {'ner': 3442.4494240283966}\n",
            "Losses {'ner': 4626.975474596024}\n",
            "Losses {'ner': 5543.857902765274}\n",
            "Losses {'ner': 6216.848343372345}\n",
            "Losses {'ner': 7115.765986442566}\n",
            "Losses {'ner': 7807.370667457581}\n",
            "Losses {'ner': 8568.343453407288}\n",
            "Losses {'ner': 9774.452157020569}\n",
            "Losses {'ner': 10677.36675786972}\n",
            "Losses {'ner': 11095.397361040115}\n",
            "Losses {'ner': 11301.073670305312}\n",
            "Starting iteration 18\n",
            "Losses {'ner': 837.0903759002686}\n",
            "Losses {'ner': 1786.6738452911377}\n",
            "Losses {'ner': 2851.4552116394043}\n",
            "Losses {'ner': 4000.3408670425415}\n",
            "Losses {'ner': 4737.528790235519}\n",
            "Losses {'ner': 5399.512044668198}\n",
            "Losses {'ner': 5976.962336778641}\n",
            "Losses {'ner': 6884.232394456863}\n",
            "Losses {'ner': 7715.706105470657}\n",
            "Losses {'ner': 8462.956939458847}\n",
            "Losses {'ner': 8691.291145140305}\n",
            "Losses {'ner': 9227.245867783204}\n",
            "Losses {'ner': 9936.52951603569}\n",
            "Losses {'ner': 10916.545877033845}\n",
            "Starting iteration 19\n",
            "Losses {'ner': 825.2551498413086}\n",
            "Losses {'ner': 1462.0119545459747}\n",
            "Losses {'ner': 2397.5371911525726}\n",
            "Losses {'ner': 3542.013046979904}\n",
            "Losses {'ner': 4167.38778758049}\n",
            "Losses {'ner': 5036.686322689056}\n",
            "Losses {'ner': 5656.500545501709}\n",
            "Losses {'ner': 6470.71608543396}\n",
            "Losses {'ner': 7177.836618423462}\n",
            "Losses {'ner': 7773.448322296143}\n",
            "Losses {'ner': 8992.570761203766}\n",
            "Losses {'ner': 9601.4351644516}\n",
            "Losses {'ner': 10701.680402755737}\n",
            "Losses {'ner': 11074.56108045578}\n",
            "Starting iteration 20\n",
            "Losses {'ner': 820.1480693817139}\n",
            "Losses {'ner': 1018.3096556067467}\n",
            "Losses {'ner': 1825.913286626339}\n",
            "Losses {'ner': 2373.780269086361}\n",
            "Losses {'ner': 2721.712793171406}\n",
            "Losses {'ner': 3499.2211049199104}\n",
            "Losses {'ner': 4436.886614143848}\n",
            "Losses {'ner': 5341.895302593708}\n",
            "Losses {'ner': 6551.955437481403}\n",
            "Losses {'ner': 7668.534678280354}\n",
            "Losses {'ner': 8058.932654678822}\n",
            "Losses {'ner': 9003.254180967808}\n",
            "Losses {'ner': 9708.494273722172}\n",
            "Losses {'ner': 10821.757550776005}\n",
            "Starting iteration 21\n",
            "Losses {'ner': 917.6910824775696}\n",
            "Losses {'ner': 1461.6659388542175}\n",
            "Losses {'ner': 2235.3984632492065}\n",
            "Losses {'ner': 3188.281936645508}\n",
            "Losses {'ner': 3808.3980226516724}\n",
            "Losses {'ner': 4974.5011510849}\n",
            "Losses {'ner': 6168.103762626648}\n",
            "Losses {'ner': 6793.260088920593}\n",
            "Losses {'ner': 7634.038934707642}\n",
            "Losses {'ner': 8200.818558216095}\n",
            "Losses {'ner': 8802.186323165894}\n",
            "Losses {'ner': 9566.514469146729}\n",
            "Losses {'ner': 10112.489546775818}\n",
            "Losses {'ner': 10965.853823661804}\n",
            "Starting iteration 22\n",
            "Losses {'ner': 1079.1708099842072}\n",
            "Losses {'ner': 1819.4098255634308}\n",
            "Losses {'ner': 2686.8961141109467}\n",
            "Losses {'ner': 3487.5339906215668}\n",
            "Losses {'ner': 4363.853428602219}\n",
            "Losses {'ner': 5139.345642089844}\n",
            "Losses {'ner': 5680.7028948664665}\n",
            "Losses {'ner': 6805.677481353283}\n",
            "Losses {'ner': 7291.401427447796}\n",
            "Losses {'ner': 8207.07718962431}\n",
            "Losses {'ner': 9726.035689532757}\n",
            "Losses {'ner': 10366.318375766277}\n",
            "Losses {'ner': 11398.36798018217}\n",
            "Losses {'ner': 11790.64618486166}\n",
            "Starting iteration 23\n",
            "Losses {'ner': 828.3635563850403}\n",
            "Losses {'ner': 1921.7525095939636}\n",
            "Losses {'ner': 3033.1056151390076}\n",
            "Losses {'ner': 4362.663355350494}\n",
            "Losses {'ner': 4841.337258934975}\n",
            "Losses {'ner': 5668.776536107063}\n",
            "Losses {'ner': 6333.705302357674}\n",
            "Losses {'ner': 7073.721794247627}\n",
            "Losses {'ner': 7807.461319208145}\n",
            "Losses {'ner': 8330.42810678482}\n",
            "Losses {'ner': 8642.812160015106}\n",
            "Losses {'ner': 10213.283153057098}\n",
            "Losses {'ner': 10864.197412014008}\n",
            "Losses {'ner': 11428.998544216156}\n",
            "Starting iteration 24\n",
            "Losses {'ner': 491.5746192932129}\n",
            "Losses {'ner': 1411.466809272766}\n",
            "Losses {'ner': 2158.0816440582275}\n",
            "Losses {'ner': 2876.4038257598877}\n",
            "Losses {'ner': 4281.2174072265625}\n",
            "Losses {'ner': 5184.786129951477}\n",
            "Losses {'ner': 5897.91756439209}\n",
            "Losses {'ner': 6915.853587627411}\n",
            "Losses {'ner': 7525.324724674225}\n",
            "Losses {'ner': 8350.677787303925}\n",
            "Losses {'ner': 8672.992785453796}\n",
            "Losses {'ner': 9476.576720237732}\n",
            "Losses {'ner': 9977.828593373299}\n",
            "Losses {'ner': 10479.405869960785}\n",
            "Starting iteration 25\n",
            "Losses {'ner': 965.4564962387085}\n",
            "Losses {'ner': 1548.9076862335205}\n",
            "Losses {'ner': 2373.388337135315}\n",
            "Losses {'ner': 3241.161460876465}\n",
            "Losses {'ner': 3962.5468854904175}\n",
            "Losses {'ner': 4500.021772146225}\n",
            "Losses {'ner': 5266.357167959213}\n",
            "Losses {'ner': 6015.166497468948}\n",
            "Losses {'ner': 7123.490657091141}\n",
            "Losses {'ner': 7775.913985967636}\n",
            "Losses {'ner': 8399.522721409798}\n",
            "Losses {'ner': 9559.321246266365}\n",
            "Losses {'ner': 9940.15658068657}\n",
            "Losses {'ner': 10718.485481023788}\n",
            "Starting iteration 26\n",
            "Losses {'ner': 748.3797473907471}\n",
            "Losses {'ner': 1608.8360605239868}\n",
            "Losses {'ner': 2900.0400190353394}\n",
            "Losses {'ner': 4273.495662689209}\n",
            "Losses {'ner': 4479.832151710987}\n",
            "Losses {'ner': 5298.531935989857}\n",
            "Losses {'ner': 5864.014941334724}\n",
            "Losses {'ner': 6289.819764614105}\n",
            "Losses {'ner': 7223.123172283173}\n",
            "Losses {'ner': 7822.551296710968}\n",
            "Losses {'ner': 8514.846913576126}\n",
            "Losses {'ner': 8929.433447867632}\n",
            "Losses {'ner': 9781.253485709429}\n",
            "Losses {'ner': 10344.74440458417}\n",
            "Starting iteration 27\n",
            "Losses {'ner': 497.3859715461731}\n",
            "Losses {'ner': 741.9357367157936}\n",
            "Losses {'ner': 1767.040916979313}\n",
            "Losses {'ner': 2973.5979791283607}\n",
            "Losses {'ner': 4007.97100764513}\n",
            "Losses {'ner': 4415.1079776883125}\n",
            "Losses {'ner': 5430.8877175450325}\n",
            "Losses {'ner': 6296.406521141529}\n",
            "Losses {'ner': 6729.5353863835335}\n",
            "Losses {'ner': 7456.321620285511}\n",
            "Losses {'ner': 8054.3710044026375}\n",
            "Losses {'ner': 9013.87492209673}\n",
            "Losses {'ner': 9626.439107239246}\n",
            "Losses {'ner': 10285.80860644579}\n",
            "Starting iteration 28\n",
            "Losses {'ner': 401.49449145793915}\n",
            "Losses {'ner': 1113.3390276432037}\n",
            "Losses {'ner': 1673.9459002017975}\n",
            "Losses {'ner': 2320.0280528068542}\n",
            "Losses {'ner': 3240.0010979175568}\n",
            "Losses {'ner': 3941.6714816093445}\n",
            "Losses {'ner': 4423.470422744751}\n",
            "Losses {'ner': 5421.696609020233}\n",
            "Losses {'ner': 5896.0922927856445}\n",
            "Losses {'ner': 6512.7430539131165}\n",
            "Losses {'ner': 7118.797242641449}\n",
            "Losses {'ner': 8026.582187652588}\n",
            "Losses {'ner': 8876.292280197144}\n",
            "Losses {'ner': 10040.464023590088}\n",
            "Starting iteration 29\n",
            "Losses {'ner': 886.9768438339233}\n",
            "Losses {'ner': 1858.0558314323425}\n",
            "Losses {'ner': 2420.0591988563538}\n",
            "Losses {'ner': 2955.0141587257385}\n",
            "Losses {'ner': 3756.09836435318}\n",
            "Losses {'ner': 4308.023993968964}\n",
            "Losses {'ner': 4613.672338724136}\n",
            "Losses {'ner': 5267.267226457596}\n",
            "Losses {'ner': 6157.331715345383}\n",
            "Losses {'ner': 6715.642710149288}\n",
            "Losses {'ner': 7543.8245434165}\n",
            "Losses {'ner': 8342.5764965415}\n",
            "Losses {'ner': 9074.162728726864}\n",
            "Losses {'ner': 10065.774925649166}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrQHb1lZatnB"
      },
      "source": [
        "!pip install tika\n",
        "import re\n",
        "import spacy\n",
        "from tika import parser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj4s6CoBSIa9"
      },
      "source": [
        "nlp_model = spacy.load(r'/content/drive/MyDrive/nlp_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYIt2ILMacNa"
      },
      "source": [
        "#Function for converting the resume to text format\n",
        "\n",
        "def convert(path):\n",
        "    parsed_tika=parser.from_file(path)\n",
        "    d=re.sub('\\\\s+', ' ', parsed_tika[\"content\"])\n",
        "    d=re.sub('•',\"\",d)\n",
        "    return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuNLXEZ8mxnc"
      },
      "source": [
        "# Testing the model\n",
        "\n",
        "def test(resume):\n",
        " doc = nlp_model(resume)\n",
        "\n",
        " \n",
        " print(\"\\n\\n\\n__________________Skills___________________\\n\")\n",
        " for ent in doc.ents:\n",
        "  if ent.label_ == \"Skill\":\n",
        "     print(ent.text)  \n",
        " print(\"\\n__________________Educational Qualifications_______________\\n\")     \n",
        " for ent in doc.ents:\n",
        "  if ent.label_ == \"Edu\":\n",
        "     print(ent.text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYAxW-1cvmu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "905148f6-f356-4a97-e488-19bbcf736a5b"
      },
      "source": [
        "resume1=convert(r\"/content/drive/MyDrive/Amar Sr BSA.docx\")\n",
        "test(resume1)\n",
        "resume2=convert(r\"/content/drive/MyDrive/Pankaj BSA.docx\")\n",
        "test(resume2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "__________________Skills___________________\n",
            "\n",
            "Waterfall\n",
            "Scrum\n",
            "JAD\n",
            "jQuery\n",
            "JavaScript\n",
            "Java\n",
            "HTML5\n",
            "XML\n",
            "PL/SQL\n",
            "SQL\n",
            "Oracle\n",
            "Microsoft Access\n",
            "DB2\n",
            "Microsoft SQL\n",
            "JIRA\n",
            "Rally\n",
            "Confluence\n",
            "Microsoft Office\n",
            "ClearQuest\n",
            "Informatica\n",
            "Tableau\n",
            "Power BI\n",
            "SSRS\n",
            "HPALM\n",
            "Cucumber\n",
            "Selenium\n",
            "MS Office Suite\n",
            "XML\n",
            "HTML\n",
            "XML\n",
            "SQL\n",
            "Jira\n",
            "XML\n",
            "XML\n",
            "SOAP UI\n",
            "XML\n",
            "Rational Requisite Pro\n",
            "SQL\n",
            "MS Excel\n",
            "SQL\n",
            "XML\n",
            "SQL\n",
            "SQL\n",
            "Erwin\n",
            "SQL\n",
            "SQL*Plus\n",
            "SQL*Loader\n",
            "Erwin\n",
            "SQL Server\n",
            "Rational Requisite Pro\n",
            "\n",
            "__________________Educational Qualifications_______________\n",
            "\n",
            "\n",
            "Bachelors in Computer Science\n",
            "\n",
            "\n",
            "\n",
            "__________________Skills___________________\n",
            "\n",
            "SQL\n",
            "XML\n",
            "MySQL\n",
            "RUP\n",
            "Agile\n",
            "Clear Case\n",
            "Rational Clear Quest\n",
            "MS Office Suite\n",
            "Microsoft Access\n",
            "MS-SQL Server 2014/2012/2008/2005\n",
            "MYSQL 6\n",
            "HP Load Runner 7\n",
            "Java\n",
            "JavaScript\n",
            "HTML\n",
            "CSS\n",
            "XML\n",
            "J2EE\n",
            "HTML\n",
            "TCP/IP\n",
            "REST\n",
            "MS SQL\n",
            "MySQL\n",
            "JavaScript\n",
            "JavaScript\n",
            "SharePoint\n",
            "SQL\n",
            "10.2\n",
            "Microsoft Project Manager\n",
            "JIRA\n",
            "10.2\n",
            "Java\n",
            "JavaScript\n",
            "HTML\n",
            "JavaScript\n",
            "XML\n",
            "\n",
            "__________________Educational Qualifications_______________\n",
            "\n",
            "\n",
            "Bachelors in Electrical Engineering\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}